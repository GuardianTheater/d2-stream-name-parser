{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import argparse\n",
    "import cv2 as cv\n",
    "import os\n",
    "import shutil\n",
    "import imutils\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Adapted from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/label_image/label_image.py\n",
    "#\n",
    "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "def load_graph(model_file):\n",
    "    graph = tf.Graph()\n",
    "    graph_def = tf.GraphDef()\n",
    "\n",
    "    with open(model_file, \"rb\") as f:\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with graph.as_default():\n",
    "        tf.import_graph_def(graph_def)\n",
    "\n",
    "    return graph\n",
    "\n",
    "def read_tensor_from_image_file(file_name,\n",
    "                                input_height=299,\n",
    "                                input_width=299,\n",
    "                                input_mean=0,\n",
    "                                input_std=255):\n",
    "    input_name = \"file_reader\"\n",
    "    output_name = \"normalized\"\n",
    "    file_reader = tf.read_file(file_name, input_name)\n",
    "    if file_name.endswith(\".png\"):\n",
    "        image_reader = tf.image.decode_png(\n",
    "            file_reader, channels=3, name=\"png_reader\")\n",
    "    elif file_name.endswith(\".gif\"):\n",
    "        image_reader = tf.squeeze(\n",
    "            tf.image.decode_gif(file_reader, name=\"gif_reader\"))\n",
    "    elif file_name.endswith(\".bmp\"):\n",
    "        image_reader = tf.image.decode_bmp(file_reader, name=\"bmp_reader\")\n",
    "    else:\n",
    "        image_reader = tf.image.decode_jpeg(\n",
    "            file_reader, channels=3, name=\"jpeg_reader\")\n",
    "    float_caster = tf.cast(image_reader, tf.float32)\n",
    "    dims_expander = tf.expand_dims(float_caster, 0)\n",
    "    resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n",
    "    normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n",
    "    sess = tf.Session()\n",
    "    result = sess.run(normalized)\n",
    "\n",
    "    return result\n",
    "\n",
    "def load_labels(label_file):\n",
    "    label = []\n",
    "    proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\n",
    "    for l in proto_as_ascii_lines:\n",
    "        label.append(l.rstrip())\n",
    "    return label\n",
    "\n",
    "def label_image(file_name):\n",
    "    model_file = \\\n",
    "        \"d2_classifier_graph.pb\"\n",
    "    label_file = \"d2_classifier_labels.txt\"\n",
    "    input_height = 299\n",
    "    input_width = 299\n",
    "    input_mean = 0\n",
    "    input_std = 255\n",
    "    input_layer = \"input\"\n",
    "    output_layer = \"InceptionV3/Predictions/Reshape_1\"\n",
    "    \n",
    "    graph = load_graph(model_file)\n",
    "    t = read_tensor_from_image_file(\n",
    "      'forOCR/' + file_name,\n",
    "      input_height=input_height,\n",
    "      input_width=input_width,\n",
    "      input_mean=input_mean,\n",
    "      input_std=input_std)\n",
    "\n",
    "    input_name = \"import/Placeholder\"\n",
    "    output_name = \"import/final_result\"\n",
    "    input_operation = graph.get_operation_by_name(input_name)\n",
    "    output_operation = graph.get_operation_by_name(output_name)\n",
    "\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        results = sess.run(output_operation.outputs[0], {\n",
    "            input_operation.outputs[0]: t\n",
    "        })\n",
    "        results = np.squeeze(results)\n",
    "\n",
    "        top_k = results.argsort()[-5:][::-1]\n",
    "        labels = load_labels(label_file)\n",
    "        for i in top_k:\n",
    "            if results[i] > .9 and ( \\\n",
    "#                                     labels[i] == 'orbit' \\\n",
    "#                                  or \\\n",
    "#                                     labels[i] == 'pgcr' \\\n",
    "#                                  or \\\n",
    "                                    labels[i] == 'player menu' \\\n",
    "                                 or \\\n",
    "                                    labels[i] == 'roster' \\\n",
    "                                   ):\n",
    "                \n",
    "                if os.path.isdir('matches/' + labels[i]) == False:\n",
    "                    os.mkdir('matches/' + labels[i])\n",
    "                try:\n",
    "                    shutil.copy('forOCR/' + file_name, 'matches/' + labels[i] + '/' + file_name)\n",
    "                except:\n",
    "                    print('error copying ocr file')\n",
    "        try:\n",
    "            os.remove('forOCR/' + file_name)\n",
    "        except:\n",
    "            print('error removing files')\n",
    "\n",
    "def processQueue():\n",
    "    for stream in queue:\n",
    "        try:\n",
    "            file_name = str(stream['channel']['_id']) + '.jpg'\n",
    "            url = stream['preview']['template']\n",
    "            url = url.replace('{width}', '1920')\n",
    "            url = url.replace('{height}', '1080')\n",
    "            r = requests.get(url)\n",
    "            with open('forOCR/' + file_name, 'wb') as fd:\n",
    "                for chunk in r.iter_content(chunk_size=128):\n",
    "                    fd.write(chunk)\n",
    "        except:\n",
    "            print('issue retrieving 1080p screen')\n",
    "            \n",
    "def getStreams(offset = 0):\n",
    "    twitchBaseUrl = 'https://api.twitch.tv/kraken/'\n",
    "    twitchClientId = 'client_id=o8cuwhl23x5ways7456xhitdm0f4th0'\n",
    "    \n",
    "    if os.path.isdir('forOCR'):\n",
    "        shutil.rmtree('forOCR')\n",
    "    os.mkdir('forOCR')\n",
    "    \n",
    "    streamsUrl = twitchBaseUrl + 'streams?' + twitchClientId + '&game=Destiny%202&limit=100&offset=' + str(offset)\n",
    "    r = requests.get(streamsUrl)\n",
    "    json = r.json()\n",
    "    if json['streams']:\n",
    "        for stream in json['streams']:\n",
    "            if ('recov' not in stream['channel']['status']):\n",
    "                queue.append(stream)\n",
    "    if json['_total'] > offset + 100:\n",
    "        getStreams(offset + 100)\n",
    "    else:\n",
    "        processQueue()\n",
    "        \n",
    "def labelImages():\n",
    "    for filename in os.listdir('forOCR'):\n",
    "        label_image(filename)\n",
    "\n",
    "def ocrPlayerScreen(filename):\n",
    "    filepath = 'matches/player menu/' + filename\n",
    "    im_rgb = cv.imread(filepath)\n",
    "    im_crop1 = im_rgb[13:180,170:310]\n",
    "\n",
    "    im = cv.cvtColor(im_crop1, cv.COLOR_BGR2GRAY)\n",
    "    im = cv.threshold(im,150,255,cv.THRESH_BINARY_INV)[1]\n",
    "    \n",
    "    lower = np.array([0])\n",
    "    upper = np.array([15])\n",
    "    shapeMask = cv.inRange(im, lower, upper)\n",
    "\n",
    "    cnts = cv.findContours(shapeMask.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    cnts.reverse()\n",
    "\n",
    "    for c in cnts:\n",
    "        peri = cv.arcLength(c, True)\n",
    "        approx = cv.approxPolyDP(c, 0.04 * peri, True)\n",
    "\n",
    "        if len(approx) == 4:\n",
    "            (x, y, w, h) = cv.boundingRect(approx)\n",
    "            ar = w / float(h)\n",
    "            \n",
    "            if w > 7 and w < 13 and h <= 3 and ar >= 3.5:\n",
    "                \n",
    "                im_crop2 = im_rgb[y + 16:y + 60,x + 168:x+650]\n",
    "                im_crop2 = cv.cvtColor(im_crop2, cv.COLOR_BGR2GRAY)\n",
    "                im_crop2 = cv.threshold(im_crop2,150,255,cv.THRESH_BINARY_INV)[1]\n",
    "\n",
    "                try:\n",
    "                    text = pytesseract.image_to_string(im_crop2)\n",
    "                    first = text.split('\\n')[0]\n",
    "                    ascii = first.encode('ascii', 'ignore').strip().split(' ')\n",
    "                    sans_special = ''\n",
    "                    for string in ascii:\n",
    "                        if bool(re.match('[a-zA-Z0-9]+$', string)):\n",
    "                            sans_special += string + ' '\n",
    "                    stripped = sans_special.strip()\n",
    "                    twitch_id = filename.split('.')[0]\n",
    "                    if stripped:\n",
    "                        if os.path.isdir('d2-stream-name-parser/' + stripped) == False:\n",
    "                            os.mkdir('d2-stream-name-parser/' + stripped)\n",
    "                        data = {}\n",
    "                        try:\n",
    "                            with open('d2-stream-name-parser/' + stripped + '/twitch.json') as f:\n",
    "                                for i in f:\n",
    "                                    data = json.loads(i)\n",
    "\n",
    "                        except:\n",
    "                            print('new file!')\n",
    "                        if twitch_id in data:\n",
    "                            data[twitch_id] += 1\n",
    "                        else:\n",
    "                            data[twitch_id] = 1\n",
    "                        with open('d2-stream-name-parser/' + stripped + '/twitch.json', 'w+') as f:\n",
    "                            f.write(json.dumps(data))\n",
    "                except:\n",
    "                    print('issue parsing text')\n",
    "                break\n",
    "    try:\n",
    "        os.remove(filepath)\n",
    "    except:\n",
    "        print('error removing files')      \n",
    "\n",
    "def ocrRoster(filename):\n",
    "    filepath = 'matches/roster/' + filename\n",
    "    im_rgb = cv.imread(filepath)\n",
    "    im_gray = cv.cvtColor(im_rgb, cv.COLOR_BGR2GRAY)\n",
    "    im_thresh = cv.threshold(im_gray,155,255,cv.THRESH_BINARY_INV)[1]\n",
    "\n",
    "    lower = np.array([0])\n",
    "    upper = np.array([15])\n",
    "    shapeMask = cv.inRange(im_thresh, lower, upper)\n",
    "\n",
    "    cnts = cv.findContours(shapeMask.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    for c in cnts:\n",
    "        peri = cv.arcLength(c, True)\n",
    "        approx = cv.approxPolyDP(c, 0.04 * peri, True)\n",
    "\n",
    "        if len(approx) == 4:\n",
    "            (x, y, w, h) = cv.boundingRect(approx)\n",
    "            ar = w / float(h)\n",
    "\n",
    "            if ar >= .1 and ar <= .3 and h > 25:\n",
    "                crop = im_thresh[approx[2][0][1] - 40 : approx[2][0][1] , approx[0][0][0] - 415 : approx[0][0][0] - 10]\n",
    "                try:\n",
    "                    text = pytesseract.image_to_string(crop)\n",
    "                    first = text.split('\\n')[0]\n",
    "                    ascii = first.encode('ascii', 'ignore').strip().split(' ')\n",
    "                    sans_special = ''\n",
    "                    for string in ascii:\n",
    "                        if bool(re.match('[a-zA-Z0-9]+$', string)):\n",
    "                            sans_special += string + ' '\n",
    "                    stripped = sans_special.strip()\n",
    "                    q_check = stripped.split(' ')\n",
    "                    # Sometimes, the audio icon reads as a 'q', so...\n",
    "                    if q_check[-1] == 'q':\n",
    "                        q_check[-1] = ''\n",
    "                        stripped = ' '.join(q_check).strip()\n",
    "                    twitch_id = filename.split('.')[0]\n",
    "                    if stripped:\n",
    "                        if os.path.isdir('d2-stream-name-parser/' + stripped) == False:\n",
    "                            os.mkdir('d2-stream-name-parser/' + stripped)\n",
    "                        data = {}\n",
    "                        try:\n",
    "                            with open('d2-stream-name-parser/' + stripped + '/twitch.json') as f:\n",
    "                                for i in f:\n",
    "                                    data = json.loads(i)\n",
    "\n",
    "                        except:\n",
    "                            print('new file!')\n",
    "                        if twitch_id in data:\n",
    "                            data[twitch_id] += 1\n",
    "                        else:\n",
    "                            data[twitch_id] = 1\n",
    "                        with open('d2-stream-name-parser/' + stripped + '/twitch.json', 'w+') as f:\n",
    "                            f.write(json.dumps(data))\n",
    "                except:\n",
    "                    print('issue parsing text')\n",
    "                break\n",
    "    try:\n",
    "        os.remove(filepath)\n",
    "    except:\n",
    "        print('error removing files')\n",
    "\n",
    "        \n",
    "queue = []\n",
    "\n",
    "getStreams()\n",
    "labelImages()\n",
    "\n",
    "for filename in os.listdir('matches/player menu'):\n",
    "    if not filename.startswith('.'):\n",
    "        ocrPlayerScreen(filename)\n",
    "        \n",
    "for filename in os.listdir('matches/roster'):\n",
    "    if not filename.startswith('.'):\n",
    "        ocrRoster(filename)\n",
    "\n",
    "import sched, time\n",
    "\n",
    "s = sched.scheduler(time.time, time.sleep)\n",
    "def do_something(sc): \n",
    "    queue = []\n",
    "    getStreams()\n",
    "    labelImages()\n",
    "\n",
    "    for filename in os.listdir('matches/player menu'):\n",
    "        if not filename.startswith('.'):\n",
    "            ocrPlayerScreen(filename)\n",
    "\n",
    "    for filename in os.listdir('matches/roster'):\n",
    "        if not filename.startswith('.'):\n",
    "            ocrRoster(filename)\n",
    "            \n",
    "    s.enter(0, 1, do_something, (sc,))\n",
    "\n",
    "s.enter(0, 1, do_something, (s,))\n",
    "s.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
